{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c988eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando download de 26 arquivos...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        350.72\n",
       "1        361.78\n",
       "2        476.52\n",
       "3        752.56\n",
       "4       1406.71\n",
       "         ...   \n",
       "9486     354.59\n",
       "9487     338.32\n",
       "9488     309.49\n",
       "9489     278.35\n",
       "9490     260.20\n",
       "Name: val_vazaonatural, Length: 9491, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from api_dados import *\n",
    "\n",
    "nome_produto = 'dados-hidrologicos-res'\n",
    "df = coletar_dados('ons', nome_produto)\n",
    "\n",
    "df_res = df[df['nom_reservatorio'] == 'ITAPEBI']\n",
    "df_res_val= df_res['val_vazaonatural'].reset_index(drop=True)\n",
    "df_res_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f26ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def X_3d(df, janela):\n",
    "\n",
    "    data = df.to_numpy()\n",
    "    if data.ndim == 1: \n",
    "        data = data.reshape(-1, 1)\n",
    "\n",
    "    X, y = [], [] \n",
    "    for i in range(len(df) - janela):\n",
    "        X.append(data[i:i+janela, :]) # janela de features\n",
    "        y.append(data[i+janela, 0]) # alvo = primeira coluna\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def X_2d(Xseq):\n",
    "    n_samples = Xseq.shape[0]\n",
    "    return Xseq.reshape(n_samples, -1)\n",
    "\n",
    "\n",
    "X_seq_lstm, y = X_3d(df_res_val, 30)\n",
    "\n",
    "X_seq_ffn= X_2d(X_seq_lstm)\n",
    "\n",
    "input_shape_lstm = (X_seq_lstm.shape[1], X_seq_lstm.shape[2])\n",
    "input_shape_ffn = (X_seq_ffn.shape[1],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c26c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_treino_valid_teste(X, y, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):\n",
    "    \n",
    "    n = len(X)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "    # o resto vai para teste\n",
    "    n_test = n - n_train - n_val\n",
    "    \n",
    "    # Ã­ndices\n",
    "    X_train, y_train = X[:n_train], y[:n_train]\n",
    "    X_val, y_val = X[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
    "    X_test, y_test = X[n_train+n_val:], y[n_train+n_val:]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "X_train_lstm, y_train, X_val_lstm, y_val, X_test_lstm, y_test = split_treino_valid_teste(X_seq_lstm, y)\n",
    "\n",
    "X_train_ffn, y_train, X_val_ffn, y_val, X_test_ffn, y_test = split_treino_valid_teste(X_seq_ffn, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca39a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler para X (LSTM) - precisa achatar antes\n",
    "X_train_lstm_flat = X_train_lstm.reshape(X_train_lstm.shape[0], -1)\n",
    "X_val_lstm_flat   = X_val_lstm.reshape(X_val_lstm.shape[0], -1)\n",
    "X_test_lstm_flat  = X_test_lstm.reshape(X_test_lstm.shape[0], -1)\n",
    "\n",
    "scaler_X_lstm = StandardScaler()\n",
    "X_train_lstm = scaler_X_lstm.fit_transform(X_train_lstm_flat).reshape(X_train_lstm.shape)\n",
    "X_val_lstm   = scaler_X_lstm.transform(X_val_lstm_flat).reshape(X_val_lstm.shape)\n",
    "X_test_lstm  = scaler_X_lstm.transform(X_test_lstm_flat).reshape(X_test_lstm.shape)\n",
    "\n",
    "# scaler para X (FFN)\n",
    "scaler_X_ffn = StandardScaler()\n",
    "X_train_ffn = scaler_X_ffn.fit_transform(X_train_ffn)\n",
    "X_val_ffn   = scaler_X_ffn.transform(X_val_ffn)\n",
    "X_test_ffn  = scaler_X_ffn.transform(X_test_ffn)\n",
    "\n",
    "# scaler para y\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "y_val   = scaler_y.transform(y_val.reshape(-1, 1)).ravel()\n",
    "y_test  = scaler_y.transform(y_test.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b34360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "\n",
    "seed= 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b57c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# EspaÃ§o de busca global\n",
    "busca = {\n",
    "    \"num_layers\": (1, 3),                # nÃºmero de camadas minimo e maximo\n",
    "    \"units\": (64, 512, 64),              # min, max e step para nÃºmero de neurÃ´nios\n",
    "    \"dropout\": (0.0, 0.3, 0.1),          # min, max e step para dropout\n",
    "    \"learning_rate\": [1e-1, 1e-2, 1e-3],  # opÃ§Ãµes de taxa de aprendizado\n",
    "    \"batch_size\": [32, 64, 128, 256]      # opÃ§Ãµes de batch_size \n",
    "}\n",
    "\n",
    "es= EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "red_lr= ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd51837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "class CustomTuner(kt.RandomSearch):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        # usa os valores do dicionÃ¡rio busca\n",
    "        kwargs['batch_size'] = trial.hyperparameters.Choice('batch_size', values=busca[\"batch_size\"])\n",
    "\n",
    "        return super(CustomTuner, self).run_trial(trial, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7e0b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "\n",
    "def lstm_tuning(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape_lstm))\n",
    "\n",
    "    num_layers = hp.Int(\"num_layers\", busca[\"num_layers\"][0], busca[\"num_layers\"][1])\n",
    "    for i in range(num_layers):\n",
    "        return_seq = (i < num_layers - 1)\n",
    "        model.add(layers.LSTM(\n",
    "            units=hp.Int(f\"units_{i}\", \n",
    "                         min_value=busca[\"units\"][0], \n",
    "                         max_value=busca[\"units\"][1], \n",
    "                         step=busca[\"units\"][2]),\n",
    "            return_sequences=return_seq\n",
    "        ))\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float(f\"dropout_{i}\", \n",
    "                          min_value=busca[\"dropout\"][0], \n",
    "                          max_value=busca[\"dropout\"][1], \n",
    "                          step=busca[\"dropout\"][2])\n",
    "        ))\n",
    "\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice(\"learning_rate\", values=busca[\"learning_rate\"])\n",
    "        ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"mean_absolute_error\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def ffn_tuning(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape_ffn))\n",
    "    \n",
    "    num_layers = hp.Int(\"num_layers\", busca[\"num_layers\"][0], busca[\"num_layers\"][1])\n",
    "    for i in range(num_layers):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f\"units_{i}\", \n",
    "                         min_value=busca[\"units\"][0], \n",
    "                         max_value=busca[\"units\"][1], \n",
    "                         step=busca[\"units\"][2]),\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float(f\"dropout_{i}\", \n",
    "                          min_value=busca[\"dropout\"][0], \n",
    "                          max_value=busca[\"dropout\"][1], \n",
    "                          step=busca[\"dropout\"][2])\n",
    "        ))\n",
    "    \n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice(\"learning_rate\", values=busca[\"learning_rate\"])\n",
    "        ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"mean_absolute_error\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3230658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 12s]\n",
      "val_loss: 0.03725679591298103\n",
      "\n",
      "Best val_loss So Far: 0.022920265793800354\n",
      "Total elapsed time: 00h 16m 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elaine\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de busca no LSTM: 765.3 min\n",
      "Tempo de busca no FFN: 16.5 min\n",
      "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.0665 - mean_absolute_error: 0.0807\n",
      "LSTM Teste: [0.06646670401096344, 0.0806591808795929]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0757 - mean_absolute_error: 0.0890  \n",
      "FFN Teste: [0.07567929476499557, 0.08897057175636292]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# LSTM\n",
    "tuner_lstm = CustomTuner(\n",
    "    lstm_tuning,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=50,\n",
    "    executions_per_trial=1,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"lstm_tuning\"\n",
    ")\n",
    "\n",
    "inicio_lstm = time.time()\n",
    "tuner_lstm.search(\n",
    "    X_train_lstm, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val_lstm, y_val),\n",
    "    callbacks=[es, red_lr]\n",
    ")\n",
    "fim_lstm = time.time()\n",
    "tempo_lstm = (fim_lstm - inicio_lstm) / 60\n",
    "\n",
    "best_lstm = tuner_lstm.get_best_models(num_models=1)[0]\n",
    "\n",
    "\n",
    "# FFN\n",
    "tuner_ffn = CustomTuner(\n",
    "    ffn_tuning,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=50,\n",
    "    executions_per_trial=1,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"ffn_tuning\"\n",
    ")\n",
    "\n",
    "inicio_ffn = time.time()\n",
    "tuner_ffn.search(\n",
    "    X_train_ffn, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val_ffn, y_val),\n",
    "    callbacks=[es, red_lr]\n",
    ")\n",
    "fim_ffn = time.time()\n",
    "tempo_ffn = (fim_ffn - inicio_ffn) / 60\n",
    "\n",
    "best_ffn = tuner_ffn.get_best_models(num_models=1)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a8baebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de busca na LSTM: 765.3 min\n",
      "Tempo de busca na FFN: 16.5 min\n",
      "O melhor modelo LSTM possui 2,939,713 parÃ¢metros\n",
      "O melhor modelo FFN possui 12,289 parÃ¢metros\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tempo de busca na LSTM: {tempo_lstm:.1f} min\")\n",
    "print(f\"Tempo de busca na FFN: {tempo_ffn:.1f} min\")\n",
    "\n",
    "\n",
    "params_lstm = best_lstm.count_params()\n",
    "params_ffn = best_ffn.count_params()\n",
    "\n",
    "print(f\"O melhor modelo LSTM possui {params_lstm:,} parÃ¢metros\")\n",
    "print(f\"O melhor modelo FFN possui {params_ffn:,} parÃ¢metros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc290a4e",
   "metadata": {},
   "source": [
    "A LSTM contem muito mais parÃ¢metros que a FFN, pois:\n",
    "\n",
    "possui 4 blocos/portÃµes que simulam individualmente uma FFN \n",
    "\n",
    " - esquecimento, entrada, atualizaÃ§Ã£o e saÃ­da (os 4 em cada estado de tempo)\n",
    "\n",
    "<br>\n",
    "e conexÃµes com estados recorrentes que tornam o crescimento de parÃ¢metros uma funÃ§Ã£o quadrÃ¡tico ao invÃ©s de linear como na FFN\n",
    "\n",
    " - cada neurÃ´nio em h(t) se conecta com todos os neurÃ´nios em h(t-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f526e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>score_val_loss</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>units_0</th>\n",
       "      <th>dropout_0</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>units_1</th>\n",
       "      <th>dropout_1</th>\n",
       "      <th>units_2</th>\n",
       "      <th>dropout_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.021776</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>3</td>\n",
       "      <td>384</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.022001</td>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.022060</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranking  score_val_loss  num_layers  units_0  dropout_0  learning_rate  \\\n",
       "0        1        0.021776           3      512        0.1          0.001   \n",
       "1        2        0.021848           3      384        0.1          0.001   \n",
       "2        3        0.021929           2      512        0.1          0.001   \n",
       "3        4        0.022001           2      320        0.0          0.001   \n",
       "4        5        0.022060           1      192        0.2          0.010   \n",
       "\n",
       "   batch_size  units_1  dropout_1  units_2  dropout_2  \n",
       "0          32    320.0        0.2    320.0        0.2  \n",
       "1          32    448.0        0.1    256.0        0.0  \n",
       "2          32    192.0        0.2      NaN        NaN  \n",
       "3          32    320.0        0.2      NaN        NaN  \n",
       "4          32      NaN        NaN      NaN        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFN:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>score_val_loss</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>units_0</th>\n",
       "      <th>dropout_0</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>units_1</th>\n",
       "      <th>dropout_1</th>\n",
       "      <th>units_2</th>\n",
       "      <th>dropout_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>1</td>\n",
       "      <td>384</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.023287</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.023338</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.023570</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.023689</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranking  score_val_loss  num_layers  units_0  dropout_0  learning_rate  \\\n",
       "0        1        0.022920           1      384        0.2          0.010   \n",
       "1        2        0.023287           1      192        0.0          0.010   \n",
       "2        3        0.023338           1      448        0.0          0.001   \n",
       "3        4        0.023570           1      320        0.1          0.001   \n",
       "4        5        0.023689           1      448        0.1          0.010   \n",
       "\n",
       "   batch_size  units_1  dropout_1  units_2  dropout_2  \n",
       "0         256      NaN        NaN      NaN        NaN  \n",
       "1         256      NaN        NaN      NaN        NaN  \n",
       "2         128      NaN        NaN      NaN        NaN  \n",
       "3          32      NaN        NaN      NaN        NaN  \n",
       "4         256      NaN        NaN      NaN        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def gerar_tabela_melhores(tuner, num_top=5):\n",
    "    # melhores trials\n",
    "    trials = tuner.oracle.get_best_trials(num_trials=num_top)\n",
    "    lista_resultados = []\n",
    "    \n",
    "    for i, trial in enumerate(trials):\n",
    "        #valores dos hiperparÃ¢metros\n",
    "        hps = trial.hyperparameters.values\n",
    "        n_layers = hps.get('num_layers')\n",
    "        \n",
    "        # limpa parÃ¢metros de camadas que nÃ£o foram realmente usadas\n",
    "        for key in list(hps.keys()):\n",
    "            if 'units_' in key or 'dropout_' in key:\n",
    "                layer_idx = int(key.split('_')[1])\n",
    "                if layer_idx >= n_layers:\n",
    "                    hps[key] = np.nan\n",
    "        \n",
    "        # metricas de desempenho\n",
    "        hps['score_val_loss'] = trial.score\n",
    "        hps['ranking'] = i + 1\n",
    "        lista_resultados.append(hps)\n",
    "    \n",
    "    df = pd.DataFrame(lista_resultados)\n",
    "    # reorganiza as colunas\n",
    "    cols = ['ranking', 'score_val_loss', 'num_layers'] + [c for c in df.columns if c not in ['ranking', 'score_val_loss', 'num_layers']]\n",
    "    return df[cols]\n",
    "\n",
    "df_top_lstm = gerar_tabela_melhores(tuner_lstm)\n",
    "df_top_ffn = gerar_tabela_melhores(tuner_ffn)\n",
    "\n",
    "print(\"LSTM:\")\n",
    "display(df_top_lstm) # display() no Jupyter ou print() no terminal\n",
    "\n",
    "print(\"FFN:\")\n",
    "display(df_top_ffn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "410f2299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - loss: 0.0665 - mean_absolute_error: 0.0807\n",
      "Resultado do LSTM no conjunto de teste: [0.06646670401096344, 0.0806591808795929]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0757 - mean_absolute_error: 0.0890\n",
      "Resultado do FFN no conjunto de teste: [0.07567929476499557, 0.08897057175636292]\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultado do LSTM no conjunto de teste:\", best_lstm.evaluate(X_test_lstm, y_test))\n",
    "print(\"Resultado do FFN no conjunto de teste:\", best_ffn.evaluate(X_test_ffn, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679fcc2",
   "metadata": {},
   "source": [
    "Para ter uma comparaÃ§Ã£o justa em termos de parÃ¢metros dentro dos modelos e tempo gasto, vou tentar indicar um espaÃ§o de busca que leve a mais parÃ¢metros e permitir mais trials na busca da FFN ğŸ™‚\n",
    "\n",
    "<br>\n",
    "os parÃ¢metros em uma FFN sÃ£o os pesos e os bias dos neurÃ´nios, entÃ£o a quantidade total de parÃ¢metros serÃ¡ o resultado do nÃºmero de camadas e do nÃºmero de neurÃ´nios nessas camadas\n",
    "\n",
    "cada neurÃ´nio possui 1 bias e x pesos, onde x Ã© o nÃºmero de saÃ­das da camada anterior (ou a quantidade de features, caso seja a primeira camada oculta)\n",
    "\n",
    "as camadas sÃ£o dividas em entrada, camadas ocultas e saÃ­da. assim, uma FFN com 30 atributos na entrada (como as 30 vazÃµes usadas nesse experimento), 2 camadas ocultas com 512 neurÃ´nios cada e 1 saÃ­da tem o nÃºmero de parÃ¢metros calculado da seguinte forma:\n",
    "\n",
    "- a camada de entrada nÃ£o possui parÃ¢metros a serem calibrados, pois Ã© composta apenas pelos atributos de entrada  \n",
    "- a primeira camada oculta terÃ¡ (30+1)*512 parÃ¢metros  \n",
    "- a segunda terÃ¡ (512+1)*512 parÃ¢metros  \n",
    "- e a camada de saÃ­da terÃ¡ (512+1)*1 parÃ¢metros (ela possui apenas um neurÃ´nio, pois o modelo construido possui apenas uma saÃ­da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ade85398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÃºmero de parÃ¢metros: 1082369\n",
      "NÃºmero de parÃ¢metros: 8364929\n"
     ]
    }
   ],
   "source": [
    "# simulando nÃºmero de parÃ¢metros\n",
    "\n",
    "c1= 1024\n",
    "c2= 1024\n",
    "c3= 0\n",
    "c4= 0\n",
    "print(f'NÃºmero de parÃ¢metros: {(30+1)*c1+(c1+1)*c2+(c2+1)*1}')\n",
    "\n",
    "c1= 1664\n",
    "c2= 1664\n",
    "c3= 1664\n",
    "c4= 1664\n",
    "print(f'NÃºmero de parÃ¢metros: {(30+1)*c1+(c1+1)*c2+(c2+1)*c3+(c3+1)*c4+(c4+1)*1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a4955a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "busca_ffn_novo = {\n",
    "    \"num_layers\": (2, 4),\n",
    "    \"units\": (1024, 1664, 128),\n",
    "    \"dropout\": (0.0, 0.3, 0.1),\n",
    "    \"learning_rate\": [1e-1, 1e-2, 1e-3],\n",
    "    \"batch_size\": [32, 64, 128, 256]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class CustomTuner(kt.RandomSearch):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        # usa os valores do dicionÃ¡rio busca\n",
    "        kwargs['batch_size'] = trial.hyperparameters.Choice('batch_size', values=busca_ffn_novo[\"batch_size\"])\n",
    "\n",
    "        return super(CustomTuner, self).run_trial(trial, *args, **kwargs)\n",
    "    \n",
    "def ffn_tuning_novo(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape_ffn))\n",
    "    \n",
    "    num_layers = hp.Int(\"num_layers\", busca_ffn_novo[\"num_layers\"][0], busca_ffn_novo[\"num_layers\"][1])\n",
    "    for i in range(num_layers):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f\"units_{i}\", \n",
    "                         min_value=busca_ffn_novo[\"units\"][0], \n",
    "                         max_value=busca_ffn_novo[\"units\"][1], \n",
    "                         step=busca_ffn_novo[\"units\"][2]),\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float(f\"dropout_{i}\", \n",
    "                          min_value=busca_ffn_novo[\"dropout\"][0], \n",
    "                          max_value=busca_ffn_novo[\"dropout\"][1], \n",
    "                          step=busca_ffn_novo[\"dropout\"][2])\n",
    "        ))\n",
    "    \n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice(\"learning_rate\", values=busca_ffn_novo[\"learning_rate\"])\n",
    "        ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"mean_absolute_error\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ba14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 04m 31s]\n",
      "val_loss: 0.025605812668800354\n",
      "\n",
      "Best val_loss So Far: 0.025605812668800354\n",
      "Total elapsed time: 00h 04m 31s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "4                 |3                 |num_layers\n",
      "1664              |1536              |units_0\n",
      "0                 |0.2               |dropout_0\n",
      "1024              |1536              |units_1\n",
      "0                 |0.2               |dropout_1\n",
      "0.01              |0.001             |learning_rate\n",
      "32                |32                |batch_size\n",
      "1536              |1024              |units_2\n",
      "0.1               |0                 |dropout_2\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - loss: 665.1882 - mean_absolute_error: 3.4774 - val_loss: 2.8671 - val_mean_absolute_error: 1.5500 - learning_rate: 0.0100\n",
      "Epoch 2/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - loss: 0.7524 - mean_absolute_error: 0.4339 - val_loss: 0.2702 - val_mean_absolute_error: 0.2567 - learning_rate: 0.0100\n",
      "Epoch 3/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - loss: 0.6444 - mean_absolute_error: 0.3952 - val_loss: 0.2697 - val_mean_absolute_error: 0.2972 - learning_rate: 0.0100\n",
      "Epoch 4/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - loss: 0.6573 - mean_absolute_error: 0.3640 - val_loss: 0.3105 - val_mean_absolute_error: 0.2696 - learning_rate: 0.0100\n",
      "Epoch 5/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - loss: 0.6450 - mean_absolute_error: 0.3754 - val_loss: 0.2720 - val_mean_absolute_error: 0.2280 - learning_rate: 0.0100\n",
      "Epoch 6/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - loss: 0.6363 - mean_absolute_error: 0.3752 - val_loss: 0.2624 - val_mean_absolute_error: 0.2272 - learning_rate: 0.0100\n",
      "Epoch 7/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - loss: 0.6347 - mean_absolute_error: 0.3622 - val_loss: 0.2713 - val_mean_absolute_error: 0.2260 - learning_rate: 0.0100\n",
      "Epoch 8/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - loss: 0.8338 - mean_absolute_error: 0.4130 - val_loss: 0.3055 - val_mean_absolute_error: 0.2548 - learning_rate: 0.0100\n",
      "Epoch 9/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 57ms/step - loss: 0.6421 - mean_absolute_error: 0.3693 - val_loss: 0.2878 - val_mean_absolute_error: 0.2584 - learning_rate: 0.0100\n",
      "Epoch 10/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - loss: 0.6201 - mean_absolute_error: 0.3478 - val_loss: 0.2434 - val_mean_absolute_error: 0.2431 - learning_rate: 1.0000e-03\n",
      "Epoch 11/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - loss: 0.6167 - mean_absolute_error: 0.3366 - val_loss: 0.2309 - val_mean_absolute_error: 0.2345 - learning_rate: 1.0000e-03\n",
      "Epoch 12/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - loss: 0.6095 - mean_absolute_error: 0.3324 - val_loss: 0.2308 - val_mean_absolute_error: 0.2283 - learning_rate: 1.0000e-03\n",
      "Epoch 13/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - loss: 0.6048 - mean_absolute_error: 0.3333 - val_loss: 0.2315 - val_mean_absolute_error: 0.2290 - learning_rate: 1.0000e-03\n",
      "Epoch 14/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - loss: 0.5539 - mean_absolute_error: 0.3236 - val_loss: 0.1670 - val_mean_absolute_error: 0.1983 - learning_rate: 1.0000e-03\n",
      "Epoch 15/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - loss: 0.5098 - mean_absolute_error: 0.3100 - val_loss: 0.1411 - val_mean_absolute_error: 0.2003 - learning_rate: 1.0000e-03\n",
      "Epoch 16/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - loss: 0.4597 - mean_absolute_error: 0.2967 - val_loss: 0.1312 - val_mean_absolute_error: 0.1697 - learning_rate: 1.0000e-03\n",
      "Epoch 17/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - loss: 0.2666 - mean_absolute_error: 0.2290 - val_loss: 0.0891 - val_mean_absolute_error: 0.1349 - learning_rate: 1.0000e-03\n",
      "Epoch 18/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - loss: 0.1890 - mean_absolute_error: 0.1936 - val_loss: 0.0762 - val_mean_absolute_error: 0.1305 - learning_rate: 1.0000e-03\n",
      "Epoch 19/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - loss: 0.1649 - mean_absolute_error: 0.1800 - val_loss: 0.0880 - val_mean_absolute_error: 0.1367 - learning_rate: 1.0000e-03\n",
      "Epoch 20/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - loss: 0.1450 - mean_absolute_error: 0.1701 - val_loss: 0.0680 - val_mean_absolute_error: 0.1126 - learning_rate: 1.0000e-03\n",
      "Epoch 21/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - loss: 0.1391 - mean_absolute_error: 0.1690 - val_loss: 0.0693 - val_mean_absolute_error: 0.1253 - learning_rate: 1.0000e-03\n",
      "Epoch 22/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - loss: 0.1286 - mean_absolute_error: 0.1627 - val_loss: 0.0674 - val_mean_absolute_error: 0.1117 - learning_rate: 1.0000e-03\n",
      "Epoch 23/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - loss: 0.1256 - mean_absolute_error: 0.1575 - val_loss: 0.0599 - val_mean_absolute_error: 0.1075 - learning_rate: 1.0000e-03\n",
      "Epoch 24/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - loss: 0.1236 - mean_absolute_error: 0.1562 - val_loss: 0.0600 - val_mean_absolute_error: 0.1017 - learning_rate: 1.0000e-03\n",
      "Epoch 25/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - loss: 0.1233 - mean_absolute_error: 0.1545 - val_loss: 0.0556 - val_mean_absolute_error: 0.0980 - learning_rate: 1.0000e-03\n",
      "Epoch 26/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - loss: 0.1130 - mean_absolute_error: 0.1499 - val_loss: 0.0533 - val_mean_absolute_error: 0.0968 - learning_rate: 1.0000e-03\n",
      "Epoch 27/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - loss: 0.1124 - mean_absolute_error: 0.1464 - val_loss: 0.0515 - val_mean_absolute_error: 0.0986 - learning_rate: 1.0000e-03\n",
      "Epoch 28/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - loss: 0.1118 - mean_absolute_error: 0.1482 - val_loss: 0.0551 - val_mean_absolute_error: 0.1011 - learning_rate: 1.0000e-03\n",
      "Epoch 29/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - loss: 0.0981 - mean_absolute_error: 0.1383 - val_loss: 0.0507 - val_mean_absolute_error: 0.0931 - learning_rate: 1.0000e-03\n",
      "Epoch 30/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 70ms/step - loss: 0.0972 - mean_absolute_error: 0.1373 - val_loss: 0.0569 - val_mean_absolute_error: 0.0920 - learning_rate: 1.0000e-03\n",
      "Epoch 31/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - loss: 0.0969 - mean_absolute_error: 0.1368 - val_loss: 0.0516 - val_mean_absolute_error: 0.0945 - learning_rate: 1.0000e-03\n",
      "Epoch 32/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - loss: 0.0901 - mean_absolute_error: 0.1346 - val_loss: 0.0533 - val_mean_absolute_error: 0.0892 - learning_rate: 1.0000e-03\n",
      "Epoch 33/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - loss: 0.0801 - mean_absolute_error: 0.1192 - val_loss: 0.0516 - val_mean_absolute_error: 0.0880 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - loss: 0.0784 - mean_absolute_error: 0.1167 - val_loss: 0.0505 - val_mean_absolute_error: 0.0897 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - loss: 0.0766 - mean_absolute_error: 0.1172 - val_loss: 0.0509 - val_mean_absolute_error: 0.0925 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - loss: 0.0827 - mean_absolute_error: 0.1184 - val_loss: 0.0489 - val_mean_absolute_error: 0.0877 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - loss: 0.0795 - mean_absolute_error: 0.1172 - val_loss: 0.0483 - val_mean_absolute_error: 0.0875 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - loss: 0.0722 - mean_absolute_error: 0.1140 - val_loss: 0.0484 - val_mean_absolute_error: 0.0863 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - loss: 0.0781 - mean_absolute_error: 0.1165 - val_loss: 0.0481 - val_mean_absolute_error: 0.0843 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - loss: 0.0752 - mean_absolute_error: 0.1148 - val_loss: 0.0484 - val_mean_absolute_error: 0.0850 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - loss: 0.0769 - mean_absolute_error: 0.1152 - val_loss: 0.0480 - val_mean_absolute_error: 0.0865 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - loss: 0.0759 - mean_absolute_error: 0.1155 - val_loss: 0.0499 - val_mean_absolute_error: 0.0912 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - loss: 0.0761 - mean_absolute_error: 0.1141 - val_loss: 0.0487 - val_mean_absolute_error: 0.0839 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m178/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - loss: 0.0780 - mean_absolute_error: 0.1149 - val_loss: 0.0474 - val_mean_absolute_error: 0.0843 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m103/178\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0711 - mean_absolute_error: 0.1119"
     ]
    }
   ],
   "source": [
    "tuner_ffn_novo = CustomTuner(\n",
    "    ffn_tuning_novo,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=150,\n",
    "    executions_per_trial=1,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"ffn_tuning_novo\"\n",
    ")\n",
    "\n",
    "inicio_ffn_novo = time.time()\n",
    "tuner_ffn_novo.search(\n",
    "    X_train_ffn, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val_ffn, y_val),\n",
    "    callbacks=[es, red_lr]\n",
    ")\n",
    "fim_ffn_novo = time.time()\n",
    "tempo_ffn_novo = (fim_ffn_novo - inicio_ffn_novo) / 60\n",
    "\n",
    "best_ffn_novo = tuner_ffn_novo.get_best_models(num_models=1)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
