{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c988eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando download de 26 arquivos...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        350.72\n",
       "1        361.78\n",
       "2        476.52\n",
       "3        752.56\n",
       "4       1406.71\n",
       "         ...   \n",
       "9486     354.59\n",
       "9487     338.32\n",
       "9488     309.49\n",
       "9489     278.35\n",
       "9490     260.20\n",
       "Name: val_vazaonatural, Length: 9491, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from api_dados import *\n",
    "\n",
    "nome_produto = 'dados-hidrologicos-res'\n",
    "df = coletar_dados('ons', nome_produto)\n",
    "\n",
    "df_res = df[df['nom_reservatorio'] == 'ITAPEBI']\n",
    "df_res_val= df_res['val_vazaonatural'].reset_index(drop=True)\n",
    "df_res_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcoes_modelagem import *\n",
    "\n",
    "X_seq_lstm, y = X_3d(df_res_val, 30)\n",
    "\n",
    "X_seq_ffn= X_2d(X_seq_lstm)\n",
    "\n",
    "input_shape_lstm = (X_seq_lstm.shape[1], X_seq_lstm.shape[2])\n",
    "input_shape_ffn = (X_seq_ffn.shape[1],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c26c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_lstm, y_train, X_val_lstm, y_val, X_test_lstm, y_test = split_treino_valid_teste(X_seq_lstm, y)\n",
    "\n",
    "X_train_ffn, y_train, X_val_ffn, y_val, X_test_ffn, y_test = split_treino_valid_teste(X_seq_ffn, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca39a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler para X (LSTM) - precisa achatar antes\n",
    "X_train_lstm_flat = X_train_lstm.reshape(X_train_lstm.shape[0], -1)\n",
    "X_val_lstm_flat   = X_val_lstm.reshape(X_val_lstm.shape[0], -1)\n",
    "X_test_lstm_flat  = X_test_lstm.reshape(X_test_lstm.shape[0], -1)\n",
    "\n",
    "scaler_X_lstm = StandardScaler()\n",
    "X_train_lstm = scaler_X_lstm.fit_transform(X_train_lstm_flat).reshape(X_train_lstm.shape)\n",
    "X_val_lstm   = scaler_X_lstm.transform(X_val_lstm_flat).reshape(X_val_lstm.shape)\n",
    "X_test_lstm  = scaler_X_lstm.transform(X_test_lstm_flat).reshape(X_test_lstm.shape)\n",
    "\n",
    "# scaler para X (FFN)\n",
    "scaler_X_ffn = StandardScaler()\n",
    "X_train_ffn = scaler_X_ffn.fit_transform(X_train_ffn)\n",
    "X_val_ffn   = scaler_X_ffn.transform(X_val_ffn)\n",
    "X_test_ffn  = scaler_X_ffn.transform(X_test_ffn)\n",
    "\n",
    "# scaler para y\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "y_val   = scaler_y.transform(y_val.reshape(-1, 1)).ravel()\n",
    "y_test  = scaler_y.transform(y_test.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b34360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "seed= 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b57c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# espa√ßo de busca global\n",
    "busca = {\n",
    "    \"num_layers\": (1, 3),                # n√∫mero de camadas minimo e maximo\n",
    "    \"units\": (64, 512, 64),              # min, max e step para n√∫mero de neur√¥nios\n",
    "    \"dropout\": (0.0, 0.3, 0.1),          # min, max e step para dropout\n",
    "    \"learning_rate\": [1e-1, 1e-2, 1e-3],  # op√ß√µes de taxa de aprendizado\n",
    "    \"batch_size\": [32, 64, 128, 256]      # op√ß√µes de batch_size \n",
    "}\n",
    "\n",
    "es= EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "red_lr= ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd51837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "class CustomTuner(kt.RandomSearch):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        # usa os valores do dicion√°rio busca\n",
    "        kwargs['batch_size'] = trial.hyperparameters.Choice('batch_size', values=busca[\"batch_size\"])\n",
    "\n",
    "        return super(CustomTuner, self).run_trial(trial, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "\n",
    "def lstm_tuning(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape_lstm))\n",
    "\n",
    "    num_layers = hp.Int(\"num_layers\", busca[\"num_layers\"][0], busca[\"num_layers\"][1])\n",
    "    for i in range(num_layers):\n",
    "        return_seq = (i < num_layers - 1)\n",
    "        model.add(layers.LSTM(\n",
    "            units=hp.Int(f\"units_{i}\", \n",
    "                         min_value=busca[\"units\"][0], \n",
    "                         max_value=busca[\"units\"][1], \n",
    "                         step=busca[\"units\"][2]),\n",
    "            return_sequences=return_seq\n",
    "        ))\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float(f\"dropout_{i}\", \n",
    "                          min_value=busca[\"dropout\"][0], \n",
    "                          max_value=busca[\"dropout\"][1], \n",
    "                          step=busca[\"dropout\"][2])\n",
    "        ))\n",
    "\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice(\"learning_rate\", values=busca[\"learning_rate\"])\n",
    "        ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"mean_absolute_error\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def ffn_tuning(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape_ffn))\n",
    "    \n",
    "    num_layers = hp.Int(\"num_layers\", busca[\"num_layers\"][0], busca[\"num_layers\"][1])\n",
    "    for i in range(num_layers):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f\"units_{i}\", \n",
    "                         min_value=busca[\"units\"][0], \n",
    "                         max_value=busca[\"units\"][1], \n",
    "                         step=busca[\"units\"][2]),\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float(f\"dropout_{i}\", \n",
    "                          min_value=busca[\"dropout\"][0], \n",
    "                          max_value=busca[\"dropout\"][1], \n",
    "                          step=busca[\"dropout\"][2])\n",
    "        ))\n",
    "    \n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice(\"learning_rate\", values=busca[\"learning_rate\"])\n",
    "        ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"mean_absolute_error\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3230658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 12s]\n",
      "val_loss: 0.03725679591298103\n",
      "\n",
      "Best val_loss So Far: 0.022920265793800354\n",
      "Total elapsed time: 00h 16m 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elaine\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de busca no LSTM: 765.3 min\n",
      "Tempo de busca no FFN: 16.5 min\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.0665 - mean_absolute_error: 0.0807\n",
      "LSTM Teste: [0.06646670401096344, 0.0806591808795929]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0757 - mean_absolute_error: 0.0890  \n",
      "FFN Teste: [0.07567929476499557, 0.08897057175636292]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# LSTM\n",
    "tuner_lstm = CustomTuner(\n",
    "    lstm_tuning,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=50,\n",
    "    executions_per_trial=1,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"lstm_tuning\"\n",
    ")\n",
    "\n",
    "inicio_lstm = time.time()\n",
    "tuner_lstm.search(\n",
    "    X_train_lstm, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val_lstm, y_val),\n",
    "    callbacks=[es, red_lr]\n",
    ")\n",
    "fim_lstm = time.time()\n",
    "tempo_lstm = (fim_lstm - inicio_lstm) / 60\n",
    "\n",
    "best_lstm = tuner_lstm.get_best_models(num_models=1)[0]\n",
    "\n",
    "\n",
    "# FFN\n",
    "tuner_ffn = CustomTuner(\n",
    "    ffn_tuning,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=50,\n",
    "    executions_per_trial=1,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"ffn_tuning\"\n",
    ")\n",
    "\n",
    "inicio_ffn = time.time()\n",
    "tuner_ffn.search(\n",
    "    X_train_ffn, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val_ffn, y_val),\n",
    "    callbacks=[es, red_lr]\n",
    ")\n",
    "fim_ffn = time.time()\n",
    "tempo_ffn = (fim_ffn - inicio_ffn) / 60\n",
    "\n",
    "best_ffn = tuner_ffn.get_best_models(num_models=1)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a8baebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de busca na LSTM: 765.3 min\n",
      "Tempo de busca na FFN: 16.5 min\n",
      "O melhor modelo LSTM possui 2,939,713 par√¢metros\n",
      "O melhor modelo FFN possui 12,289 par√¢metros\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tempo de busca na LSTM: {tempo_lstm:.1f} min\")\n",
    "print(f\"Tempo de busca na FFN: {tempo_ffn:.1f} min\")\n",
    "\n",
    "\n",
    "params_lstm = best_lstm.count_params()\n",
    "params_ffn = best_ffn.count_params()\n",
    "\n",
    "print(f\"O melhor modelo LSTM possui {params_lstm:,} par√¢metros\")\n",
    "print(f\"O melhor modelo FFN possui {params_ffn:,} par√¢metros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc290a4e",
   "metadata": {},
   "source": [
    "<br>\n",
    "A LSTM contem muito mais par√¢metros que a FFN, pois:\n",
    "\n",
    "possui 4 blocos/port√µes que simulam individualmente uma FFN \n",
    "\n",
    " - esquecimento, entrada, atualiza√ß√£o e sa√≠da (os 4 em cada estado de tempo)\n",
    "\n",
    "<br>\n",
    "e conex√µes com estados recorrentes que tornam o crescimento de par√¢metros uma fun√ß√£o quadr√°tico ao inv√©s de linear como na FFN\n",
    "\n",
    " - cada neur√¥nio em h(t) se conecta com todos os neur√¥nios em h(t-1)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f526e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>score_val_loss</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>units_0</th>\n",
       "      <th>dropout_0</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>units_1</th>\n",
       "      <th>dropout_1</th>\n",
       "      <th>units_2</th>\n",
       "      <th>dropout_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.021776</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>3</td>\n",
       "      <td>384</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.022001</td>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.022060</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranking  score_val_loss  num_layers  units_0  dropout_0  learning_rate  \\\n",
       "0        1        0.021776           3      512        0.1          0.001   \n",
       "1        2        0.021848           3      384        0.1          0.001   \n",
       "2        3        0.021929           2      512        0.1          0.001   \n",
       "3        4        0.022001           2      320        0.0          0.001   \n",
       "4        5        0.022060           1      192        0.2          0.010   \n",
       "\n",
       "   batch_size  units_1  dropout_1  units_2  dropout_2  \n",
       "0          32    320.0        0.2    320.0        0.2  \n",
       "1          32    448.0        0.1    256.0        0.0  \n",
       "2          32    192.0        0.2      NaN        NaN  \n",
       "3          32    320.0        0.2      NaN        NaN  \n",
       "4          32      NaN        NaN      NaN        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFN:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>score_val_loss</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>units_0</th>\n",
       "      <th>dropout_0</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>units_1</th>\n",
       "      <th>dropout_1</th>\n",
       "      <th>units_2</th>\n",
       "      <th>dropout_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>1</td>\n",
       "      <td>384</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.023287</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.023338</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.023570</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.023689</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranking  score_val_loss  num_layers  units_0  dropout_0  learning_rate  \\\n",
       "0        1        0.022920           1      384        0.2          0.010   \n",
       "1        2        0.023287           1      192        0.0          0.010   \n",
       "2        3        0.023338           1      448        0.0          0.001   \n",
       "3        4        0.023570           1      320        0.1          0.001   \n",
       "4        5        0.023689           1      448        0.1          0.010   \n",
       "\n",
       "   batch_size  units_1  dropout_1  units_2  dropout_2  \n",
       "0         256      NaN        NaN      NaN        NaN  \n",
       "1         256      NaN        NaN      NaN        NaN  \n",
       "2         128      NaN        NaN      NaN        NaN  \n",
       "3          32      NaN        NaN      NaN        NaN  \n",
       "4         256      NaN        NaN      NaN        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df_top_lstm = gerar_tabela_melhores(tuner_lstm)\n",
    "df_top_ffn = gerar_tabela_melhores(tuner_ffn)\n",
    "\n",
    "print(\"LSTM:\")\n",
    "display(df_top_lstm) # display() no Jupyter ou print() no terminal\n",
    "\n",
    "print(\"FFN:\")\n",
    "display(df_top_ffn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "410f2299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - loss: 0.0665 - mean_absolute_error: 0.0807\n",
      "Resultado do LSTM no conjunto de teste: [0.06646670401096344, 0.0806591808795929]\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0757 - mean_absolute_error: 0.0890\n",
      "Resultado do FFN no conjunto de teste: [0.07567929476499557, 0.08897057175636292]\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultado do LSTM no conjunto de teste:\", best_lstm.evaluate(X_test_lstm, y_test))\n",
    "print(\"Resultado do FFN no conjunto de teste:\", best_ffn.evaluate(X_test_ffn, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679fcc2",
   "metadata": {},
   "source": [
    "<br>\n",
    "Para ter uma compara√ß√£o justa em termos de par√¢metros dentro dos modelos e tempo gasto, vou tentar indicar um espa√ßo de busca que leve a mais par√¢metros e permitir mais trials na busca da FFN üôÇ\n",
    "\n",
    "<br>\n",
    "os par√¢metros em uma FFN s√£o os pesos e os bias dos neur√¥nios, ent√£o a quantidade total de par√¢metros ser√° o resultado do n√∫mero de camadas e do n√∫mero de neur√¥nios nessas camadas\n",
    "\n",
    "cada neur√¥nio possui 1 bias e x pesos, onde x √© o n√∫mero de sa√≠das da camada anterior (ou a quantidade de features, caso seja a primeira camada oculta)\n",
    "\n",
    "as camadas s√£o dividas em entrada, camadas ocultas e sa√≠da. assim, uma FFN com 30 atributos na entrada (como as 30 vaz√µes usadas nesse experimento), 2 camadas ocultas com 512 neur√¥nios cada e 1 sa√≠da tem o n√∫mero de par√¢metros calculado da seguinte forma:\n",
    "\n",
    "- a camada de entrada n√£o possui par√¢metros a serem calibrados, pois √© composta apenas pelos atributos de entrada  \n",
    "- a primeira camada oculta ter√° (30+1)*512 par√¢metros  \n",
    "- a segunda ter√° (512+1)*512 par√¢metros  \n",
    "- e a camada de sa√≠da ter√° (512+1)*1 par√¢metros (ela possui apenas um neur√¥nio, pois o modelo construido possui apenas uma sa√≠da)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ade85398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de par√¢metros: 1082369\n",
      "N√∫mero de par√¢metros: 8364929\n"
     ]
    }
   ],
   "source": [
    "# simulando n√∫mero de par√¢metros\n",
    "\n",
    "c1= 1024\n",
    "c2= 1024\n",
    "c3= 0\n",
    "c4= 0\n",
    "print(f'N√∫mero de par√¢metros: {(30+1)*c1+(c1+1)*c2+(c2+1)*1}')\n",
    "\n",
    "c1= 1664\n",
    "c2= 1664\n",
    "c3= 1664\n",
    "c4= 1664\n",
    "print(f'N√∫mero de par√¢metros: {(30+1)*c1+(c1+1)*c2+(c2+1)*c3+(c3+1)*c4+(c4+1)*1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4955a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "busca_ffn_novo = {\n",
    "    \"num_layers\": (2, 4),\n",
    "    \"units\": (1024, 1664, 128),\n",
    "    \"dropout\": (0.0, 0.3, 0.1),\n",
    "    \"learning_rate\": [1e-1, 1e-2, 1e-3],\n",
    "    \"batch_size\": [32, 64, 128, 256]\n",
    "}\n",
    "\n",
    "\n",
    "class CustomTuner(kt.RandomSearch):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        # usa os valores do dicion√°rio busca\n",
    "        kwargs['batch_size'] = trial.hyperparameters.Choice('batch_size', values=busca_ffn_novo[\"batch_size\"])\n",
    "\n",
    "        return super(CustomTuner, self).run_trial(trial, *args, **kwargs)\n",
    "    \n",
    "def ffn_tuning_novo(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape_ffn))\n",
    "    \n",
    "    num_layers = hp.Int(\"num_layers\", busca_ffn_novo[\"num_layers\"][0], busca_ffn_novo[\"num_layers\"][1])\n",
    "    for i in range(num_layers):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f\"units_{i}\", \n",
    "                         min_value=busca_ffn_novo[\"units\"][0], \n",
    "                         max_value=busca_ffn_novo[\"units\"][1], \n",
    "                         step=busca_ffn_novo[\"units\"][2]),\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float(f\"dropout_{i}\", \n",
    "                          min_value=busca_ffn_novo[\"dropout\"][0], \n",
    "                          max_value=busca_ffn_novo[\"dropout\"][1], \n",
    "                          step=busca_ffn_novo[\"dropout\"][2])\n",
    "        ))\n",
    "    \n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice(\"learning_rate\", values=busca_ffn_novo[\"learning_rate\"])\n",
    "        ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"mean_absolute_error\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d16ba14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 150 Complete [00h 02m 31s]\n",
      "val_loss: 5.302131175994873\n",
      "\n",
      "Best val_loss So Far: 0.02299734763801098\n",
      "Total elapsed time: 06h 49m 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elaine\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "tuner_ffn_novo = CustomTuner(\n",
    "    ffn_tuning_novo,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=150,\n",
    "    executions_per_trial=1,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"ffn_tuning_novo\"\n",
    ")\n",
    "\n",
    "inicio_ffn_novo = time.time()\n",
    "tuner_ffn_novo.search(\n",
    "    X_train_ffn, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val_ffn, y_val),\n",
    "    callbacks=[es, red_lr]\n",
    ")\n",
    "fim_ffn_novo = time.time()\n",
    "tempo_ffn_novo = (fim_ffn_novo - inicio_ffn_novo) / 60\n",
    "\n",
    "best_ffn_novo = tuner_ffn_novo.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a890bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de busca na nova FFN: 409.5 min\n",
      "O melhor modelo FFN novo possui 2,209,409 par√¢metros\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tempo de busca na nova FFN: {tempo_ffn_novo:.1f} min\")\n",
    "\n",
    "params_ffn_novo = best_ffn_novo.count_params()\n",
    "print(f\"O melhor modelo FFN novo possui {params_ffn_novo:,} par√¢metros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "896e4e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFN novo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>score_val_loss</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>units_0</th>\n",
       "      <th>dropout_0</th>\n",
       "      <th>units_1</th>\n",
       "      <th>dropout_1</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>units_2</th>\n",
       "      <th>dropout_2</th>\n",
       "      <th>units_3</th>\n",
       "      <th>dropout_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.022997</td>\n",
       "      <td>2</td>\n",
       "      <td>1408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.023055</td>\n",
       "      <td>2</td>\n",
       "      <td>1152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>2</td>\n",
       "      <td>1280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.023536</td>\n",
       "      <td>2</td>\n",
       "      <td>1408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.023879</td>\n",
       "      <td>2</td>\n",
       "      <td>1664</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1280</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranking  score_val_loss  num_layers  units_0  dropout_0  units_1  \\\n",
       "0        1        0.022997           2     1408        0.0     1536   \n",
       "1        2        0.023055           2     1152        0.0     1024   \n",
       "2        3        0.023451           2     1280        0.0     1408   \n",
       "3        4        0.023536           2     1408        0.0     1280   \n",
       "4        5        0.023879           2     1664        0.2     1280   \n",
       "\n",
       "   dropout_1  learning_rate  batch_size  units_2  dropout_2  units_3  \\\n",
       "0        0.1          0.001         256      NaN        NaN      NaN   \n",
       "1        0.1          0.001         256      NaN        NaN      NaN   \n",
       "2        0.0          0.001         128      NaN        NaN      NaN   \n",
       "3        0.0          0.001         128      NaN        NaN      NaN   \n",
       "4        0.1          0.001         256      NaN        NaN      NaN   \n",
       "\n",
       "   dropout_3  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_top_ffn_novo = gerar_tabela_melhores(tuner_ffn_novo)\n",
    "\n",
    "print(\"FFN novo:\")\n",
    "display(df_top_ffn_novo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef325c",
   "metadata": {},
   "source": [
    "<br>\n",
    "Mesmo ap√≥s essa busca por um modelo com mais par√¢metros internos para serem calibrados, o novo melhor modelo FFN n√£o obteve resultados melhores no conjunto de valida√ß√£o. Al√©m disso, os melhores modelos continuaram a escolher o menor n√∫mero de camadas permitidas na busca: duas.\n",
    "<br>\n",
    "\n",
    "Para o conjunto de treinamento, os resultados foram os seguintes:\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a8199a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error no conjunto de teste:\n",
      "lstm: 0.066462\n",
      "ffn: 0.075683\n",
      "ffn novo: 0.074079\n",
      "\n",
      "Teste de wilcoxon pareado para os residuos dos modelos\n",
      "p-valor de lstm x ffn: 0.000000\n",
      "p-valor de lstm x ffn novo: 0.066849\n"
     ]
    }
   ],
   "source": [
    "y_pred_lstm = best_lstm.predict(X_test_lstm, verbose=0).ravel()\n",
    "y_pred_ffn = best_ffn.predict(X_test_ffn, verbose=0).ravel()\n",
    "y_pred_ffn_novo = best_ffn_novo.predict(X_test_ffn, verbose=0).ravel()\n",
    "\n",
    "residuos_lstm = y_test - y_pred_lstm\n",
    "residuos_ffn = y_test - y_pred_ffn\n",
    "residuos_ffn_novo = y_test - y_pred_ffn_novo\n",
    "\n",
    "print('mean squared error no conjunto de teste:')\n",
    "print(f'lstm: {np.mean(residuos_lstm**2):.6f}')\n",
    "print(f'ffn: {np.mean(residuos_ffn**2):.6f}')\n",
    "print(f'ffn novo: {np.mean(residuos_ffn_novo**2):.6f}')\n",
    "\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# teste 1: LSTM vs FFN\n",
    "statistic_lstm_ffn, p_value_lstm_ffn = wilcoxon(\n",
    "    np.abs(residuos_lstm), \n",
    "    np.abs(residuos_ffn),\n",
    "    alternative='less'\n",
    ")\n",
    "\n",
    "# teste 2: LSTM vs FFN novo\n",
    "statistic_lstm_ffn_novo, p_value_lstm_ffn_novo = wilcoxon(\n",
    "    np.abs(residuos_lstm), \n",
    "    np.abs(residuos_ffn_novo),\n",
    "    alternative='less'\n",
    ")\n",
    "\n",
    "print()\n",
    "print('Teste de wilcoxon pareado para os residuos dos modelos')\n",
    "print(f\"p-valor de lstm x ffn: {p_value_lstm_ffn:.6f}\")\n",
    "print(f\"p-valor de lstm x ffn novo: {p_value_lstm_ffn_novo:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bbe683",
   "metadata": {},
   "source": [
    "<br>\n",
    "Conclus√£o: mesmo ap√≥s a nova tentativa, os valores da melhor LSTM foram mais precisos que os da melhor FFN tanto nos dados de valida√ß√£o quanto nos dados de teste üôÇ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
